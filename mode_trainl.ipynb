{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Identify the model -> YOLO\n",
        "\n",
        "Image classification Object Detection Instance segmentation\n",
        "\n",
        "video, images, audio, text\n",
        "\n",
        "Object detection\n",
        "\n",
        "Model - yolo 11\n",
        "decide what object to identify - Umbrella (done)\n",
        "\n",
        "Gather our dataset (done)\n",
        "\n",
        "Labe;/Annotate\n",
        "\n",
        "Train\n",
        "\n",
        "Validation\n",
        "\n",
        "Inference"
      ],
      "metadata": {
        "id": "8KXh_s3jwV5M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJm86vDi36AH",
        "outputId": "88b21d44-4dbf-45ca-973c-962c598e9493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.179-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.15-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.179-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.15-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tIl7cU8c4I5h",
        "outputId": "40d708bc-8831-476f-8a41-e2be812d1851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Aug 16 16:10:18 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8wvgsapg4KW5"
      },
      "outputs": [],
      "source": [
        "# Unzip images to a custom data folder\n",
        "!unzip -q /content/data.zip -d /content/custom_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zUrpsbd849sq",
        "outputId": "269f0992-a7ae-4787-8a93-a6dba99de040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory specified by --datapath not found. Verify the path is correct (and uses double back slashes if on Windows) and try again.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import shutil # Import shutil for moving files\n",
        "from pathlib import Path # Import Path\n",
        "\n",
        "\n",
        "script_content = \"\"\"\n",
        "# Split between train and val folders\n",
        "\n",
        "from pathlib import Path\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import argparse\n",
        "import glob # Added glob import\n",
        "\n",
        "# Define and parse user input arguments\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--datapath', help='Path to data folder containing image and annotation files',\n",
        "                    required=True)\n",
        "parser.add_argument('--imagepath', help='Path to data folder containing image and annotation files',\n",
        "                    required=True)\n",
        "parser.add_argument('--labelpath', help='Path to data folder containing image and annotation files',\n",
        "                    required=True)\n",
        "parser.add_argument('--train_pct', help='Ratio of images to go to train folder; \\\\\n",
        "                    the rest go to validation folder (example: \".8\")',\n",
        "                    default=.8)\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "data_path = args.datapath\n",
        "image_path = args.imagepath\n",
        "label_path = args.labelpath\n",
        "train_percent = float(args.train_pct)\n",
        "\n",
        "# Check for valid entries\n",
        "if not os.path.isdir(data_path):\n",
        "   print('Directory specified by --datapath not found. Verify the path is correct (and uses double back slashes if on Windows) and try again.')\n",
        "   sys.exit(0)\n",
        "if train_percent < .01 or train_percent > 0.99:\n",
        "   print('Invalid entry for train_pct. Please enter a number between .01 and .99.')\n",
        "   sys.exit(0)\n",
        "val_percent = 1 - train_percent\n",
        "\n",
        "# Define paths to image and annotation folders\n",
        "# Modified to use the data_path directly\n",
        "input_image_path = image_path\n",
        "input_label_path = label_path\n",
        "\n",
        "cwd = os.getcwd()\n",
        "train_img_path = os.path.join(cwd,'data/train/images')\n",
        "train_txt_path = os.path.join(cwd,'data/train/labels')\n",
        "val_img_path = os.path.join(cwd,'data/validation/images')\n",
        "val_txt_path = os.path.join(cwd,'data/validation/labels')\n",
        "\n",
        "# Create folders if they don't already exist\n",
        "for dir_path in [train_img_path, train_txt_path, val_img_path, val_txt_path]:\n",
        "   if not os.path.exists(dir_path):\n",
        "      os.makedirs(dir_path)\n",
        "      print(f'Created folder at {dir_path}.')\n",
        "\n",
        "\n",
        "# Get list of all images and annotation files directly from datapath\n",
        "img_file_list = [Path(f) for f in glob.glob(os.path.join(input_image_path, \"*.*\")) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"))]\n",
        "txt_file_list = [Path(f) for f in glob.glob(os.path.join(input_label_path, \"*.txt\"))]\n",
        "\n",
        "print(f'Number of image files: {len(img_file_list)}')\n",
        "print(f'Number of annotation files: {len(txt_file_list)}')\n",
        "\n",
        "# Pair image and label files with the same base name\n",
        "paired_files = []\n",
        "for img_path in img_file_list:\n",
        "    label_filename = img_path.with_suffix('.txt').name\n",
        "    label_path = Path(input_label_path) / label_filename\n",
        "    if label_path.exists():\n",
        "        paired_files.append((img_path, label_path))\n",
        "\n",
        "# Determine number of files to move to each folder based on paired files\n",
        "file_num = len(paired_files)\n",
        "train_num = int(file_num * train_percent)\n",
        "val_num = file_num - train_num\n",
        "print('Images moving to train: %d' % train_num)\n",
        "print('Images moving to validation: %d' % val_num)\n",
        "\n",
        "# Shuffle the paired files and split into train and validation sets\n",
        "random.shuffle(paired_files)\n",
        "train_files = paired_files[:train_num]\n",
        "val_files = paired_files[train_num:]\n",
        "\n",
        "# Copy train images and annotations to train folders\n",
        "for img_path, label_path in train_files:\n",
        "    image_filename = img_path.name\n",
        "    annotation_filename = label_path.name\n",
        "    src_image_path = str(img_path)\n",
        "    src_annotation_path = str(label_path)\n",
        "    dest_image_path = os.path.join(train_img_path, image_filename)\n",
        "    dest_annotation_path = os.path.join(train_txt_path, annotation_filename)\n",
        "    shutil.copy(src_image_path, dest_image_path)\n",
        "    shutil.copy(src_annotation_path, dest_annotation_path)\n",
        "    #print(f'Copied {image_filename} and {annotation_filename} to train')\n",
        "\n",
        "\n",
        "# Copy validation images and annotations to validation folders\n",
        "for img_path, label_path in val_files:\n",
        "    image_filename = img_path.name\n",
        "    annotation_filename = label_path.name\n",
        "    src_image_path = str(img_path)\n",
        "    src_annotation_path = str(label_path)\n",
        "    dest_image_path = os.path.join(val_img_path, image_filename)\n",
        "    dest_annotation_path = os.path.join(val_txt_path, annotation_filename)\n",
        "    shutil.copy(src_image_path, dest_image_path)\n",
        "    shutil.copy(src_annotation_path, dest_annotation_path)\n",
        "    #print(f'Copied {image_filename} and {annotation_filename} to validation')\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "with open('/content/train_val_split.py', 'w') as f:\n",
        "    f.write(script_content)\n",
        "\n",
        "\n",
        "# Run the modified script\n",
        "!python train_val_split.py --datapath=\"/content/custom_data\" --imagepath=\"/content/custom_data/images\" --labelpath=\"/content/custom_data/labels\" --train_pct=0.8 #0.9 --> 90% training rest for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vq77wb0N5n2D",
        "outputId": "4ad8bd6a-14ad-4370-eb4d-f0ddacf73214"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "classes.txt file not found! Please create a classes.txt labelmap and move it to /content/custom_data/classes.txt\n",
            "\n",
            "File contents:\n",
            "\n",
            "cat: /content/data.yaml: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Python function to automatically create data.yaml config file\n",
        "# 1. Reads \"classes.txt\" file to get list of class names\n",
        "# 2. Creates data dictionary with correct paths to folders, number of classes, and names of classes\n",
        "# 3. Writes data in YAML format to data.yaml\n",
        "\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "def create_data_yaml(path_to_classes_txt, path_to_data_yaml):\n",
        "\n",
        "  # Read class.txt to get class names\n",
        "  if not os.path.exists(path_to_classes_txt):\n",
        "    print(f'classes.txt file not found! Please create a classes.txt labelmap and move it to {path_to_classes_txt}')\n",
        "    return\n",
        "  with open(path_to_classes_txt, 'r') as f:\n",
        "    classes = []\n",
        "    for line in f.readlines():\n",
        "      if len(line.strip()) == 0: continue\n",
        "      classes.append(line.strip())\n",
        "  number_of_classes = len(classes)\n",
        "\n",
        "  # Create data dictionary\n",
        "  data = {\n",
        "      'path': '/content/data',\n",
        "      'train': 'train/images',\n",
        "      'val': 'validation/images',\n",
        "      'nc': number_of_classes,\n",
        "      'names': classes\n",
        "  }\n",
        "\n",
        "  # Write data to YAML file\n",
        "  with open(path_to_data_yaml, 'w') as f:\n",
        "    yaml.dump(data, f, sort_keys=False)\n",
        "  print(f'Created config file at {path_to_data_yaml}')\n",
        "\n",
        "  return\n",
        "\n",
        "# Define path to classes.txt and run function\n",
        "path_to_classes_txt = '/content/custom_data/classes.txt'\n",
        "path_to_data_yaml = '/content/data.yaml'\n",
        "\n",
        "create_data_yaml(path_to_classes_txt, path_to_data_yaml)\n",
        "\n",
        "print('\\nFile contents:\\n')\n",
        "!cat /content/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aWssasE5_rT"
      },
      "outputs": [],
      "source": [
        "!yolo detect train data=/content/data.yaml model=yolo11s.pt epochs=100 imgsz=640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqtAJrqI6nlw"
      },
      "outputs": [],
      "source": [
        "!yolo detect predict model=runs/detect/train/weights/best.pt source=data/validation/images save=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlM_iLGU61Xq"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "for image_path in glob.glob(f'/content/runs/detect/predict/*.jpg')[:10]:\n",
        "  display(Image(filename=image_path, height=600, width=900))\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca-MIcSr8Xbj"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/my_model\n",
        "!cp /content/runs/detect/train/weights/best.pt /content/my_model/my_model.pt\n",
        "!cp -r /content/runs/detect/train /content/my_model\n",
        "\n",
        "# Zip\n",
        "%cd my_model\n",
        "!zip /content/my_model.zip my_model.pt\n",
        "!zip -r /content/my_model.zip train\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLb3NkCX8bVj"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the model\n",
        "model = YOLO(\"/content/my_model/my_model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJazzoho8qV6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Run inference on an image\n",
        "results = model(\"/content/chh.jpg\", conf=0.3)\n",
        "print(results)\n",
        "# Process results\n",
        "for r in results:\n",
        "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
        "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
        "    # Convert the PIL Image to a numpy array (OpenCV format)\n",
        "    im_cv2 = cv2.cvtColor(np.array(im), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Display the image using cv2_imshow\n",
        "    cv2_imshow(im_cv2)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44100d3f"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the model\n",
        "model = YOLO(\"/content/my_model/my_model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdHJgOh2ArNW"
      },
      "outputs": [],
      "source": [
        "# Run inference on a video\n",
        "# Replace \"your_video.mp4\" with the path to your video file\n",
        "results = model(\"/content/vv.mp4\", conf=0.5, save=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTqOFNuM_JK8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import display, Video\n",
        "\n",
        "# Define the path to the saved video. Assumes the video is saved in 'runs/detect/predict'\n",
        "# You might need to adjust the path based on the actual output directory of the previous cell.\n",
        "output_dir = 'runs/detect/predict3'\n",
        "# Find the latest created video file in the output directory\n",
        "video_files = [f for f in os.listdir(output_dir) if f.endswith(('.mp4', '.avi'))]\n",
        "video_files.sort(key=lambda x: os.path.getmtime(os.path.join(output_dir, x)))\n",
        "\n",
        "if video_files:\n",
        "    video_path = os.path.join(output_dir, video_files[-1])\n",
        "    print(f\"Displaying video from: {video_path}\")\n",
        "\n",
        "    # Display the video directly in the notebook\n",
        "    display(Video(video_path, embed=True))\n",
        "else:\n",
        "    print(\"No video file found in the output directory.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}